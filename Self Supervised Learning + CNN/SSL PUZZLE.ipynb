{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"collapsed_sections":["HXssZo27o7Uj","aVL93tCao7U0","-XNdP6kBo7U5","5mL_RRsNo7U9","yQhudCO8o7VG"]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# LIBRARIES"],"metadata":{"id":"HXssZo27o7Uj"}},{"cell_type":"code","source":["import torch\n","import json\n","import os\n","import pandas as pd\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import scipy\n","import collections\n","from PIL import Image\n","import pickle\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models.mobilenetv2 import Conv2dNormActivation, InvertedResidual\n","import torch.optim as optim\n","import itertools\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import precision_score, recall_score, f1_score"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:43:58.504898Z","iopub.execute_input":"2024-06-17T10:43:58.505970Z","iopub.status.idle":"2024-06-17T10:44:05.990974Z","shell.execute_reply.started":"2024-06-17T10:43:58.505901Z","shell.execute_reply":"2024-06-17T10:44:05.989748Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"xCKGHJpUo7Uu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CUDA"],"metadata":{"id":"aVL93tCao7U0"}},{"cell_type":"code","source":["# Train on GPU if available\n","train_on_gpu = torch.cuda.is_available()\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","\n","device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n","\n","print(device)"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:44:05.992768Z","iopub.execute_input":"2024-06-17T10:44:05.993309Z","iopub.status.idle":"2024-06-17T10:44:06.001412Z","shell.execute_reply.started":"2024-06-17T10:44:05.993244Z","shell.execute_reply":"2024-06-17T10:44:06.000170Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"1--QWNIbo7U2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IMPORT THE DATASET"],"metadata":{"id":"-XNdP6kBo7U5"}},{"cell_type":"code","source":["'''\n","\n","This part of the code serves the purpose of dowloading\n","the dataset in a proper way for kaggle. A file json is created\n","to download the dataset from kaggle.\n","\n","'''\n","\n","# Create file kaggle.json to download from Kaggle\n","kaggle_json = {\n","    \"username\": \"enricomarta\",\n","    \"key\": \"84d386ad7a7c02ed584cae00085f289b\"\n","}\n","\n","# Path of the kaggle.json\n","kaggle_json_path = '/kaggle/working/kaggle.json'\n","\n","# Write on kaggle.json\n","with open(kaggle_json_path, 'w') as file:\n","    json.dump(kaggle_json, file)\n","\n","# Kaggle's enviornment\n","os.environ['KAGGLE_CONFIG_DIR'] = '/kaggle/working'\n","\n","# Correctness of the information\n","!chmod 600 /kaggle/working/kaggle.json\n","\n","print(\"Downloading the dataset from Kaggle...\")\n","!kaggle competitions download -c ifood-2019-fgvc6 -p /kaggle/working --force"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:44:06.002662Z","iopub.execute_input":"2024-06-17T10:44:06.003031Z","iopub.status.idle":"2024-06-17T10:44:39.131449Z","shell.execute_reply.started":"2024-06-17T10:44:06.002996Z","shell.execute_reply":"2024-06-17T10:44:39.130206Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"LkvpGQV5o7U6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# unzip files\n","!unzip -o ifood-2019-fgvc6.zip -d /kaggle/working > /dev/null\n","!unzip -o train_set.zip -d /kaggle/working > /dev/null\n","\n","!ls"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:44:39.134909Z","iopub.execute_input":"2024-06-17T10:44:39.135390Z","iopub.status.idle":"2024-06-17T10:45:39.810625Z","shell.execute_reply.started":"2024-06-17T10:44:39.135347Z","shell.execute_reply":"2024-06-17T10:45:39.809275Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"WpOlESJHo7U6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove unnecesary files for the project\n","!rm class_list.txt ifood-2019-fgvc6.zip sample_submission.csv ifood2019_sample_submission.csv test_set.zip train_set.zip val_labels.csv val_set.zip"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:45:39.812871Z","iopub.execute_input":"2024-06-17T10:45:39.813282Z","iopub.status.idle":"2024-06-17T10:45:41.653602Z","shell.execute_reply.started":"2024-06-17T10:45:39.813232Z","shell.execute_reply":"2024-06-17T10:45:41.652005Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"QAgTkF4Zo7U8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PRE-PROCESSING"],"metadata":{"id":"5mL_RRsNo7U9"}},{"cell_type":"code","source":["'''\n","Here training and validation set are created and saved.\n","Then number of images contained in both are providded.\n","'''\n","\n","# path of the csv file\n","file_path = '/kaggle/working/train_labels.csv'\n","data = pd.read_csv(file_path)\n","\n","# Split the data into training and validation sets (30% for validation)\n","train_data, validation_data = train_test_split(data, test_size=0.3, stratify=data['label'], random_state=42)\n","\n","# Save the validation set\n","validation_data.to_csv('validation_set.csv', index=False)\n","\n","# Save the training set\n","train_data.to_csv('training_set.csv', index=False)\n","\n","num_train_rows = train_data.shape[0]\n","num_validation_rows = validation_data.shape[0]\n","print(f\"Number of rows in the training set: {num_train_rows}\")\n","print(f\"Number of rows in the validation set: {num_validation_rows}\")"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:45:41.655571Z","iopub.execute_input":"2024-06-17T10:45:41.656057Z","iopub.status.idle":"2024-06-17T10:45:42.042609Z","shell.execute_reply.started":"2024-06-17T10:45:41.656015Z","shell.execute_reply":"2024-06-17T10:45:42.041473Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"uRbOypRVo7VA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Here the 'final dataset' is created, augmenting\n","under-represented classes via duplication, and then saved.\n","'''\n","\n","# Path of the CSV file\n","file_path = '/kaggle/working/training_set.csv'\n","\n","# Upload the CSV file\n","data = pd.read_csv(file_path)\n","\n","# Number of rows\n","num_rows = data.shape[0]\n","#print(f\"Number of rows: {num_rows}\")\n","\n","# Number of labels\n","num_labels = data['label'].nunique()\n","#print(f\"Number of labels: {num_labels}\")\n","\n","# Number of observations for each label\n","images_per_label = data['label'].value_counts()\n","#print(\"Number of images per label (ascending order):\")\n","#print(images_per_label.sort_values().head(10))\n","\n","# Find classes with fewer than 300 observations\n","classes_to_duplicate = images_per_label[images_per_label < 300].index\n","\n","# DataFrame for the duplicate images\n","duplicated_data = []\n","\n","# For each label that doesn't have enough images\n","for label in classes_to_duplicate:\n","    rows_to_duplicate = data[data['label'] == label]\n","    # Calculate how many more images are needed to reach 300\n","    count_needed = 300 - len(rows_to_duplicate)\n","    # Generates a sample of duplicate rows from the current class\n","    duplicated_rows = rows_to_duplicate.sample(n=count_needed, replace=True, random_state=1)\n","    # Concatenates the original rows together with the duplicated rows\n","    duplicated_data.append(pd.concat([rows_to_duplicate, duplicated_rows], ignore_index=True))\n","\n","# Merge all positions contained in the list\n","final_duplicated_data = pd.concat(duplicated_data, ignore_index=True)\n","\n","# Well represented data (already have 300 or more observations)\n","well_represented_data = data[data['label'].value_counts()[data['label']].values >= 300]\n","\n","# Merge to obtain the final new dataframe\n","final_data = pd.concat([well_represented_data, final_duplicated_data], ignore_index=True)\n","\n","# Create the new file CSV\n","final_file_path = '/kaggle/working/modified_train_labels.csv'\n","final_data.to_csv(final_file_path, index=False)\n","\n","# New Training Dataset\n","data_modified = pd.read_csv(final_file_path)\n","num_rows_modified = len(data_modified)\n","print(f\"Number of images in modified file: {num_rows_modified}\")\n","images_per_label_mod = data_modified['label'].value_counts()\n","print(\"Number of images per label (ascending order):\")\n","print(images_per_label_mod.sort_values().head(10))"],"metadata":{"execution":{"iopub.status.busy":"2024-06-17T10:49:13.527006Z","iopub.execute_input":"2024-06-17T10:49:13.528686Z","iopub.status.idle":"2024-06-17T10:49:13.939012Z","shell.execute_reply.started":"2024-06-17T10:49:13.528641Z","shell.execute_reply":"2024-06-17T10:49:13.937783Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"HYbuW-dIo7VC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Here the class 'FoodDataset is created.\n","It provides an appropriate way to manage images.\n","'''\n","\n","class FoodDataset(Dataset):\n","\n","    def __init__(self, root_dir, transform, split):\n","        \"\"\"\n","        Args:\n","            root_dir (string): Directory containing the images.\n","            transform (callable, optional): Transformation to be applied to the images.\n","            split (string): Split type (\"train\" or \"val\").\n","        \"\"\"\n","        self.split = split\n","        self.root_dir = root_dir\n","        self.data = self.get_data_train()\n","        self.data_v = self.get_data_val()\n","\n","        if split == \"train\":\n","            self.data = self.data\n","        elif split == \"val\":\n","            self.data = self.data_v\n","        self.transform = transform\n","\n","    def get_data_train(self):\n","        df = pd.read_csv('/kaggle/working/training_set.csv')\n","        # Construct full image paths using vectorized operations\n","        df['img_name'] = self.root_dir + \"/\" + df['img_name']\n","        # Filter for images with existing paths using vectorized boolean indexing\n","        df = df[df['img_name'].apply(os.path.exists)]\n","        return df.to_numpy()  # Return preprocessed data as a NumPy array\n","\n","    def get_data_val(self):\n","        df = pd.read_csv('/kaggle/working/validation_set.csv')\n","        # Construct full image paths using vectorized operations\n","        df['img_name'] = self.root_dir + \"/\" + df['img_name']\n","        # Filter for images with existing paths using vectorized boolean indexing\n","        df = df[df['img_name'].apply(os.path.exists)]\n","        return df.to_numpy()  # Return preprocessed data as a NumPy array\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the length of the dataset (number of samples).\n","\n","        This method overrides the default behavior of `len` for the dataset object.\n","        It simply returns the length of the internal `data` list, which represents\n","        the preprocessed data after loading and filtering.\n","        \"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Retrieves a sample at a given index.\n","\n","        This method overrides the default behavior of indexing for the dataset object.\n","        It takes an index `idx` and performs the following:\n","            1. Accesses the image name and num_class at the specified index from `self.data`.\n","            2. Opens the image using `Image.open` with the full path constructed by\n","               combining `self.root_dir` and `img_name`.\n","            3. Applies the defined transformation (`self.transform`) to the image.\n","            4. Creates a dictionary `sample` containing the preprocessed image (`image`)\n","               and the num_class as a PyTorch tensor (`torch.tensor(num_class).float()`).\n","            5. Returns the constructed `sample` dictionary.\n","        \"\"\"\n","        img_name, num_class = self.data[idx]\n","        image = Image.open(os.path.join(self.root_dir, img_name))\n","        image = self.transform(image)\n","\n","        sample = {'img_name': image, 'labels': torch.tensor(num_class).float()}\n","        return sample\n"],"metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:30:04.389911Z","iopub.execute_input":"2024-06-15T20:30:04.390354Z","iopub.status.idle":"2024-06-15T20:30:08.832402Z","shell.execute_reply.started":"2024-06-15T20:30:04.390317Z","shell.execute_reply":"2024-06-15T20:30:08.831662Z"},"trusted":true,"id":"QYQ0AVGWo7VD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Functions for data transformation are provided,\n","distinguishing between trainin and validation sets.\n","Creation of Dataloaders.\n","'''\n","transform_train = transforms.Compose([\n","    transforms.Resize((256, 256)),  # Resize images to 256x256\n","    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally with a probability of 50%\n","    transforms.RandomAffine(degrees=0, shear=0.2),  # Apply random shear transformations\n","    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0), ratio=(1.0, 1.0)),  # Apply random zoom transformations\n","    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n","    transforms.Normalize(  # Normalize pixel values based on ImageNet statistics\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","transform_val = transforms.Compose([\n","    transforms.Resize((256, 256)),  # Resize images to 256x256 (consistent with training)\n","    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n","    transforms.Normalize(  # Normalize pixel values using the same statistics\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","\n","# Set batch size\n","bs = 100\n","\n","# Create datasets for training and validation\n","trainset = FoodDataset(\"/kaggle/working/train_set\", transform_train, split=\"train\")\n","valset = FoodDataset(\"/kaggle/working/train_set\", transform_val, split=\"val\")\n","\n","# Create data loaders for efficient batch training and evaluation\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False)\n","\n","# Print dataset and dataloader lengths (number of samples and batches)\n","print(f\"Number of training samples: {len(trainloader) * bs}\")\n","print(f\"Number of validation samples: {len(valloader)}\")"],"metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:30:08.833458Z","iopub.execute_input":"2024-06-15T20:30:08.833849Z","iopub.status.idle":"2024-06-15T20:30:10.085246Z","shell.execute_reply.started":"2024-06-15T20:30:08.833825Z","shell.execute_reply":"2024-06-15T20:30:10.084363Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"48XwBer-o7VF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"yQhudCO8o7VG"}},{"cell_type":"code","source":["'''\n","Here the architecture of the CNN is provided,\n","two different classifiers.\n","Additional functions for SSL pretext task are present.\n","\n","'''\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Let's create a reduced version of MobileNetV2 (lower than 1 million)\n","        self.features = nn.Sequential(\n","            Conv2dNormActivation(3, 32, kernel_size=3, stride=2, padding=1),\n","            InvertedResidual(32, 16, stride=1, expand_ratio=1),\n","            InvertedResidual(16, 24, stride=2, expand_ratio=6),\n","            InvertedResidual(24, 24, stride=1, expand_ratio=6),\n","            InvertedResidual(24, 32, stride=2, expand_ratio=6),\n","            InvertedResidual(32, 32, stride=1, expand_ratio=6),\n","            InvertedResidual(32, 32, stride=1, expand_ratio=6),\n","            InvertedResidual(32, 64, stride=2, expand_ratio=6),\n","            InvertedResidual(64, 64, stride=1, expand_ratio=6),\n","            InvertedResidual(64, 64, stride=1, expand_ratio=6),\n","            InvertedResidual(64, 64, stride=1, expand_ratio=6),\n","            InvertedResidual(64, 96, stride=1, expand_ratio=6),\n","            InvertedResidual(96, 96, stride=2, expand_ratio=6),\n","            InvertedResidual(96, 96, stride=2, expand_ratio=6),\n","            Conv2dNormActivation(96, 800, kernel_size=1, stride=1, padding=0)\n","        )\n","\n","        # Definition of the classifiers (one ending with 9, the other 251)\n","        self.classifier_puzzle = self._create_classifier(9)\n","        self.classifier_true = self._create_classifier(251)\n","\n","    def _create_classifier(self, num_classes):\n","        return nn.Sequential(\n","            nn.Linear(800, 445),\n","            nn.GELU(),\n","            nn.Linear(445, 32),\n","            nn.GELU(),\n","            nn.Linear(32, num_classes)\n","        )\n","    # Forward common to both classifiers\n","    def forward_shared(self, x):\n","        x = self.features(x)\n","        x = nn.functional.adaptive_avg_pool2d(x, (1, 1)).flatten(1)\n","        return x\n","    # Forward for puzzle classifier\n","    def forward_puzzle(self, x):\n","        x = self.forward_shared(x)\n","        x = self.classifier_puzzle(x)\n","        return x\n","    # Forward for true classifier\n","    def forward_true(self, x):\n","        x = self.forward_shared(x)\n","        x = self.classifier_true(x)\n","        return x\n","\n","    def _preprocess(self, images):\n","        \"\"\"\n","        Preprocess the input images to generate puzzles and create corresponding targets.\n","\n","        Parameters:\n","            images (Tensor): Batch of input images.\n","\n","        Returns:\n","            images_batch (Tensor): Batch of shuffled puzzle pieces.\n","            targets (Tensor): Corresponding targets for the original puzzle piece positions.\n","        \"\"\"\n","        batch_size, channels, height, width = images.shape\n","        grid_size = 3\n","        piece_height = height // grid_size\n","        piece_width = width // grid_size\n","\n","        # Create grid indices\n","        indices = torch.arange(grid_size * grid_size).view(grid_size, grid_size)\n","\n","        # Extract pieces and create the puzzle\n","        pieces = []\n","        targets = []\n","        for i in range(grid_size):\n","            for j in range(grid_size):\n","                piece = images[:, :, i*piece_height:(i+1)*piece_height, j*piece_width:(j+1)*piece_width]\n","                pieces.append(piece)\n","                targets.append(indices[i, j].repeat(batch_size))\n","\n","        pieces = torch.stack(pieces, dim=1)  # Shape: [batch_size, num_pieces, channels, piece_height, piece_width]\n","        targets = torch.stack(targets, dim=1)  # Shape: [batch_size, num_pieces]\n","\n","        # Shuffle the pieces\n","        shuffled_indices = torch.randperm(grid_size * grid_size)\n","        shuffled_pieces = pieces[:, shuffled_indices, :, :, :]\n","        shuffled_targets = targets[:, shuffled_indices]\n","\n","        # Flatten the pieces and targets\n","        shuffled_pieces = shuffled_pieces.view(-1, channels, piece_height, piece_width)\n","        shuffled_targets = shuffled_targets.view(-1)\n","\n","        return shuffled_pieces, shuffled_targets\n","\n","\n","net = Net()\n","net.to(device)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:30:10.088118Z","iopub.execute_input":"2024-06-15T20:30:10.088418Z","iopub.status.idle":"2024-06-15T20:30:10.402056Z","shell.execute_reply.started":"2024-06-15T20:30:10.088392Z","shell.execute_reply":"2024-06-15T20:30:10.401035Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"aROkk8Clo7VH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING and EVALUATION"],"metadata":{"id":"9K2iZxt8o7VJ"}},{"cell_type":"code","source":["'''\n","Define training parameters (epochs, loss function, optimizer, and scheduler)\n","Threee different optimizers for shared, puzzle, true.\n","'''\n","\n","epochs = 60  # Number of training epochs\n","criterion = nn.CrossEntropyLoss()  # Cross Entropy loss function for classification\n","\n","optimizer_shared = optim.Adam(net.features.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n","scheduler_shared = CosineAnnealingLR(optimizer_shared,\n","                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n","                              eta_min=1e-5)  # Minimum learning rate for scheduler\n","optimizer_puzzle = optim.Adam(net.classifier_puzzle.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n","scheduler_puzzle = CosineAnnealingLR(optimizer_puzzle,\n","                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n","                              eta_min=1e-5)  # Minimum learning rate for scheduler\n","optimizer_true = optim.Adam(net.classifier_true.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n","scheduler_true = CosineAnnealingLR(optimizer_true,\n","                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n","                              eta_min=1e-5)  # Minimum learning rate for scheduler\n"],"metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:30:10.403815Z","iopub.execute_input":"2024-06-15T20:30:10.404193Z","iopub.status.idle":"2024-06-15T20:30:10.506132Z","shell.execute_reply.started":"2024-06-15T20:30:10.404159Z","shell.execute_reply":"2024-06-15T20:30:10.505382Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"R3bV3fgjo7VK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Training and Validation section.\n","'''\n","\n","# Uncomment if you need to complete the training\n","#net.load_state_dict(torch.load(\"/kaggle/input/vecchio/net_best.pth\"))\n","\n","# Parameters for the early stopping procedure\n","patience = 3\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","\n","# Lists to evaluate the final model\n","all_preds = []\n","all_labels = []\n","all_preds_true = []\n","all_labels_true = []\n","\n","# Training\n","for epoch in range(epochs)\n","\n","    running_loss = []  # Store puzzle's training loss for each batch\n","    running_loss_true = [] # Store true training loss for each batch\n","    net.train()\n","\n","    for i, data in enumerate(trainloader):\n","\n","        # Get inputs and labels from the data loader\n","        inputs, labels = data[\"img_name\"], data[\"labels\"]\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","\n","        # Zero the parameter gradients before each backward pass\n","        optimizer_shared.zero_grad()\n","        optimizer_puzzle.zero_grad()\n","\n","        # Generation of the training images and labels for puzzle's task\n","        shuffled_pieces, targets = net._preprocess(inputs)\n","        shuffled_pieces, targets = shuffled_pieces.to(device), targets.to(device)\n","\n","        # Forward procedure for puzzle's task\n","        outputs = net.forward_puzzle(shuffled_pieces)\n","        outputs = outputs.to(device)\n","\n","        # Loss for puzzle's task\n","        loss = criterion(outputs.squeeze(), targets)\n","        # Backward pass and parameter update\n","        loss.backward()\n","        optimizer_shared.step()\n","        optimizer_puzzle.step()\n","\n","        # Let's do the same for true task\n","        optimizer_shared.zero_grad()\n","        optimizer_true.zero_grad()\n","        outputs_true = net.forward_true(inputs)\n","        outputs_true = outputs_true.to(device)\n","        loss_true = criterion(outputs_true.squeeze(), labels)\n","        loss_true.backward()\n","        optimizer_true.step()\n","\n","        # Update the scheduler\n","        scheduler_shared.step()\n","        scheduler_puzzle.step()\n","        scheduler_true.step()\n","\n","        running_loss.append(loss.item())\n","        running_loss_true.append(loss_true.item())\n","        # Print statistics (every 10% of the training data)\n","        if (i + 1) % (len(trainloader) // 10) == 0:\n","            print('%d, [%d, %d] loss puzzle: %.4f\\tlr: %.6f\\tloss true: %.6f' %\n","                  (epoch + 1, i + 1, len(trainloader), np.mean(running_loss), optimizer_true.param_groups[-1]['lr'],np.mean(running_loss_true)))\n","            running_loss = []\n","            running_loss_true = []\n","    # Validation\n","    running_loss = []  # List to store validation loss for each batch\n","    running_loss_true = []\n","    net.eval()  # Set the model to evaluation mode\n","\n","    # Variables for Evaluation of the model\n","    correct = 0\n","    total = 0\n","    total_true = 0\n","    correct_true = 0\n","\n","    for i, data in enumerate(valloader):\n","        # Get inputs and labels from the data loader\n","        inputs, labels = data[\"img_name\"], data[\"labels\"]\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","\n","        shuffled_pieces, targets = net._preprocess(inputs)\n","        shuffled_pieces, targets = shuffled_pieces.to(device), targets.to(device)\n","        # Forward pass with gradient suppression\n","        with torch.no_grad():\n","            outputs = net.forward_puzzle(shuffled_pieces)\n","            outputs = outputs.to(device)\n","\n","            # Finds the class with the highest probability for each image in the batch.\n","            _, predicted = torch.max(outputs.cpu(), 1)\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(targets.cpu().numpy())\n","            # label.size(0) gives the batch size\n","            total += targets.size(0)\n","            # True positives\n","            correct += (predicted == targets.cpu()).sum().item()\n","\n","\n","            # Same for the true task\n","            outputs_true = net.forward_true(inputs)\n","            outputs_true = outputs_true.to(device)\n","            _, predicted_true = torch.max(outputs_true.cpu(), 1)\n","            all_preds_true.extend(predicted_true.cpu().numpy())\n","            all_labels_true.extend(labels.cpu().numpy())\n","            total_true += labels.size(0)\n","            correct_true += (predicted_true == labels.cpu()).sum().item()\n","        # Calculate loss for puzzle\n","        loss = criterion(outputs, targets)\n","        running_loss.append(loss.item())\n","\n","        # Calculate true loss\n","        loss_true = criterion(outputs_true, labels)\n","        running_loss_true.append(loss_true.item())\n","    # Calculate mean of true and puzzle's validation loss\n","    val_loss = np.mean(running_loss)\n","    val_loss_true = np.mean(running_loss_true)\n","\n","    print('Validation loss puzzle: %.6f\\tValidation loss true: %.6f' % (val_loss, val_loss_true))\n","    # Calculate accuracy\n","    accuracy = 100 * correct / total\n","    accuracy_true = 100 * correct_true / total_true\n","    print(f'Validation accuracy puzzle: {accuracy:.2f} %\\tValidation accuracy true: {accuracy_true:.2f} %')\n","\n","    # Early stopping procedure if no improvement in puzzle validation loss\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","\n","        torch.save(net.state_dict(), \"net_best.pth\")\n","        print(f\"Epoch {epoch+1}: Validation loss puzzle improved to {val_loss:.6f}. Model saved.\")\n","    else:\n","        epochs_no_improve += 1\n","        print(f\"Epoch {epoch+1}: No improvement in validation loss ({val_loss:.6f}). Epochs without improvement: {epochs_no_improve}/{patience}\")\n","    if epochs_no_improve == patience:\n","        print(f\"Early stopping triggered after {epoch+1} epochs. Best validation loss: {best_val_loss:.6f}\")\n","        break\n","\n","\n","print('Finished Training')\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2024-06-15T20:30:10.507285Z","iopub.execute_input":"2024-06-15T20:30:10.507580Z"},"jupyter":{"source_hidden":true},"trusted":true,"id":"iLtIDSTto7VL"},"execution_count":null,"outputs":[]}]}